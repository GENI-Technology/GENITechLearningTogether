{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM9tmPYA0OyNHHJPeFiPlpH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "52922bddfc5d4844aec6a29da290532f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35428debe85a4494a742970eb9dea703",
              "IPY_MODEL_6ffff0ee51a349aa8adb39a231472317",
              "IPY_MODEL_636125f5e63541ff861360a1ba5d1611"
            ],
            "layout": "IPY_MODEL_dd8061524f544f0daee5b94ce251ed98"
          }
        },
        "35428debe85a4494a742970eb9dea703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ffe847ecb3a422fac408544069d1b2f",
            "placeholder": "​",
            "style": "IPY_MODEL_2e3c115bc75b4766a44b8ef61d8fead1",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6ffff0ee51a349aa8adb39a231472317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93eb987f7e914d0dab6bfcb6b2513ce6",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86185c3635424ba8bf157d98addd3854",
            "value": 3
          }
        },
        "636125f5e63541ff861360a1ba5d1611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68e6efb01fbd426a9c16316c5993aae1",
            "placeholder": "​",
            "style": "IPY_MODEL_285978cbcbaa4a82b1b4b7724601c802",
            "value": " 3/3 [00:56&lt;00:00, 20.24s/it]"
          }
        },
        "dd8061524f544f0daee5b94ce251ed98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ffe847ecb3a422fac408544069d1b2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e3c115bc75b4766a44b8ef61d8fead1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93eb987f7e914d0dab6bfcb6b2513ce6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86185c3635424ba8bf157d98addd3854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68e6efb01fbd426a9c16316c5993aae1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "285978cbcbaa4a82b1b4b7724601c802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GENI-Technology/GENITechLearningTogether/blob/main/Weight_Transfer_within_Identical_Transformer_Models_V001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://geni.asia/wp-content/uploads/2021/12/Full_logo_Color.png\" alt=\"GENI Technology (Myanmar)\" width=\"150\">\n"
      ],
      "metadata": {
        "id": "WgPq2T4ZoG-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Acknowledgments**\n",
        "\n",
        "This tutorial was created with the help of several valuable resources and collaborations.\n",
        "\n",
        "* **Large Language Models:** We would like to acknowledge the valuable assistance of **Google Gemini** and **ChatGPT** for their capabilities in language generation and information retrieval. These large language models were instrumental in providing insights and generating draft text, which were subsequently refined and edited for clarity and accuracy.\n",
        "* **Research Team:** We are grateful to [GENI Technology research team](https://geni.asia/research-internship-batch-1/) for their contributions, guidance, and support throughout the development of this tutorial. Their expertise and collaboration were essential for ensuring the quality and comprehensiveness of this work.\n",
        "\n",
        "We hope this tutorial proves to be informative and helpful. Please feel free to reach out if you have any questions or feedback.\n",
        "\n"
      ],
      "metadata": {
        "id": "IMo5XMQLelZy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "Have you ever found yourself in a situation where you need to adapt an existing **source model** (i.e., pretrained transformer model) for a new task, but its vocabulary does not quite match the available data? Perhaps you need to switch tokenizers to better handle the specific domain of your new task.\n",
        "\n",
        "This can be especially tricky when the source model's **embedding layer**, which maps words to numerical representations, relies on the original tokenizer's vocabulary. Changing the tokenizer means the word meanings encoded in the embedding layer no longer align with the new vocabulary.\n",
        "\n",
        "This guide will walk you through a specific solution for tackling this challenge. We will explore how to **transfer weights** from a **destination model** that uses the desired tokenizer to your source model. This approach involves copying the **embedding layer weights** and potentially some **encoder layer weights** from the destination model to your source model.\n",
        "\n",
        "By the end of this tutorial, you will be equipped to:\n",
        "\n",
        "* Understand the rationale behind weight transfer in this scenario.\n",
        "* Implement the process of transferring embedding and encoder layer weights from the destination to the source model.\n",
        "* Fine-tune the source model to adapt it to your specific task and dataset (**Coming Soon!**).\n",
        "\n",
        "This approach allows you to leverage the knowledge and understanding of the destination model's trained weights while adapting your source model to work effectively with your new tokenizer and task data.\n"
      ],
      "metadata": {
        "id": "qD0kM7O5BzLy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why This Approach Works\n",
        "\n",
        "The approach of transferring weights from a destination model to a source model with a mismatched tokenizer works due to two key factors: **vocabulary alignment** and **leveraging pre-trained knowledge**.\n",
        "\n",
        "**1. Vocabulary Alignment**\n",
        "\n",
        "When you replace the source model's tokenizer with the destination model's tokenizer, their vocabularies become **aligned**. This means that the words and their corresponding numerical representations (embeddings) are consistent between the two models.\n",
        "\n",
        "By transferring the **embedding layer weights** from the destination model to the source model, you directly copy the pre-trained word representations that are already aligned with the new vocabulary. This ensures that the source model understands the meanings of words within the new vocabulary without needing to retrain the entire embedding layer from scratch.\n",
        "\n",
        "**2. Leveraging Pre-trained Knowledge**\n",
        "\n",
        "Beyond just vocabulary alignment, transferring **encoder layer weights**, particularly from earlier layers, can be beneficial. The **encoder** is responsible for capturing relationships between words and extracting meaningful features from the sequence of embeddings.\n",
        "\n",
        "By transferring some encoder layer weights from the destination model, you potentially leverage the knowledge it has learned about these features in the context of the new vocabulary. This can:\n",
        "\n",
        "* **Improve feature understanding** The transferred weights might encode better ways to extract meaningful features from the aligned sequences of embeddings.\n",
        "* **Accelerate training** The transferred weights can provide the source model with a good starting point for training, potentially allowing it to reach a strong performance level faster compared to training from scratch.\n",
        "\n",
        "**Important to Note:**\n",
        "\n",
        "* **Fine-tuning is crucial:** Even after transferring weights, **fine-tuning** the source model on your specific task and dataset is essential. This allows the model to adapt to any nuances specific to your data that might not have been perfectly captured by the destination model.\n",
        "* **Partial transfer might be optimal:** Not all encoder layers need to be transferred. It's worth experimenting to see if focusing on earlier layers that typically capture more general language features is beneficial.\n",
        "\n",
        "``\n",
        "Overall, transferring weights from a destination model with a matching tokenizer to a source model allows you to efficiently adapt the source model to a new task while leveraging the pre-trained knowledge gained by the destination model.\n",
        "``"
      ],
      "metadata": {
        "id": "oRAoyOqID2OM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up the Environment in Google Colab\n",
        "\n",
        "This section guides you through setting up the necessary libraries for this tutorial within a Google Colab environment.\n",
        "\n",
        "**Google Colab:** Google Colab is a free platform that allows you to run Python code in your web browser, eliminating the need for local installations. It provides access to powerful hardware resources like GPUs, making it ideal for computationally intensive tasks like deep learning.\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "1. **Open Google Colab:** Visit [https://research.google.com/colaboratory/](https://research.google.com/colaboratory/) in your web browser.\n",
        "2. **Create a New Notebook:** Click on \"File\" -> \"New Notebook\" to create a new notebook where we will execute the code.\n",
        "\n",
        "**Installing Required Libraries:**\n",
        "\n",
        "The following code snippet installs the necessary libraries for this tutorial:\n",
        "\n",
        "```python\n",
        "!pip install -q -U bitsandbytes transformers peft accelerate datasets trl einops\n",
        "```\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "* `!pip`: This symbol indicates a system command executed within the Colab environment.\n",
        "* `install`: This keyword specifies the action to be performed, which is installing packages.\n",
        "* `-q`: This flag suppresses output from the installation process, keeping the notebook cleaner.\n",
        "* `-U`: This flag ensures that the latest version of each library is installed, if available.\n",
        "* `bitsandbytes`, `transformers`, `peft`, `accelerate`, `datasets`, `trl`, `einops`: These are the names of the libraries we need to install.\n",
        "\n",
        "**Running the Code:**\n",
        "\n",
        "1. Click inside the first code cell (the box containing the above code).\n",
        "2. Press \"Shift\" + \"Enter\" or click the \"Run\" button (play symbol) at the top of the cell to execute the code.\n",
        "\n",
        "**Verification:**\n",
        "\n",
        "Once the code execution is complete, you should see no errors or warnings in the output below the code cell. This indicates that the libraries have been successfully installed in your Colab environment.\n",
        "\n",
        "**Additional Notes:**\n",
        "\n",
        "* You may need to restart your Colab runtime occasionally, especially after installing new libraries. This ensures that the changes are reflected in the environment.\n",
        "* Google Colab has resource limitations for free usage. If you encounter any resource issues, you might need to upgrade to a paid tier or adjust your code for efficiency."
      ],
      "metadata": {
        "id": "MLYDWh7PF2Vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U transformers\n",
        "!pip install -q -U peft\n",
        "!pip install -q -U accelerate\n",
        "!pip install -q -U datasets\n",
        "!pip install -q -U trl\n",
        "!pip install -q -U einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W_qmdopcpDq",
        "outputId": "dd5ef956-333c-47bf-93c2-64337c120329"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Core NLP Libraries**\n",
        "\n",
        "* **transformers (from Hugging Face):** This is a powerhouse library for NLP. It provides:\n",
        "    * **Pre-trained Models:** Vast collection of state-of-the-art Transformer-based models for tasks like text classification, translation, question answering, etc.  Think of them as 'brains' already trained on massive amounts of data.\n",
        "    * **Tokenizers:**  Tools to break sentences into wordpieces that the models understand.\n",
        "    * **Pipelines:** Easy-to-use components for common NLP tasks.\n",
        "\n",
        "* **datasets (from Hugging Face):**  A centralized platform for accessing and using a huge range of publicly available datasets for NLP. You can load many common datasets for training or evaluation purposes with minimal effort.\n",
        "\n",
        "**Specialized for Transfer Learning & Efficiency**\n",
        "\n",
        "* **peft:** Facilitates fine-tuning of pre-trained models with specialized techniques and flexibility. Crucial for effectively adapting models to your specific downstream tasks.\n",
        "\n",
        "* **trl:** Another transfer learning library. While less well-known, it might have specific utilities for certain weight transfer or knowledge distillation approaches.\n",
        "\n",
        "* **accelerate (from Hugging Face):** Optimizes training across different hardware (CPUs, GPUs, TPUs) and simplifies distributed training (using multiple computing units simultaneously for faster training).\n",
        "\n",
        "* **bitsandbytes:** Helps with quantization of models. This reduces model size and computational cost, making models fit into resource-limited environments or run more efficiently.\n",
        "\n",
        "* **einops:** Provides a flexible and intuitive way to manipulate and reshape tensors (the fundamental data structures within NLP models). This can streamline code for complex tensor operations.\n",
        "\n",
        "**How They Work Together**\n",
        "\n",
        "In this tutorial setup, these libraries work in conjunction to:\n",
        "\n",
        "1. Load pre-trained models (`transformers`) and their associated tokenizers, potentially from a destination model that aligns with your new task.\n",
        "2. Extract relevant weights from the destination model related to embeddings or encoder layers.\n",
        "3. Transfer and incorporate these weights into your source model.\n",
        "4. Leverage the other libraries to optimize (`accelerate`, `bitsandbytes`) and fine-tune (`peft`) your enhanced source model on your specific downstream task while using relevant datasets (`datasets`).\n"
      ],
      "metadata": {
        "id": "b8OoR7RhGxGb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Essential Libraries for NLP and Transfer Learning\n",
        "\n",
        "This section dives into the various libraries imported for this tutorial and their roles in enabling the transfer learning approach:\n",
        "\n",
        "**From Transformers:**\n",
        "\n",
        "* **AutoModelForCausalLM:** Loads any pre-trained causal language model (like GPT-2) from the Hugging Face model hub based on a model identifier. In our case, it will be used for the source model.\n",
        "* **AutoTokenizer:** Automatically loads the tokenizer associated with the chosen model (from AutoModelForCausalLM) for handling text pre-processing and tokenization.\n",
        "* **BitsAndBytesConfig:** Configuration for model quantization using BitsAndBytes library (potentially used for efficiency improvements).\n",
        "* **HfArgumentParser:** Helps parse command-line arguments for fine-tuning, making hyperparameter tuning and experiment management easier.\n",
        "* **TrainingArguments:** Defines training arguments like learning rate, epochs, etc., for fine-tuning the model.\n",
        "* **pipeline:** Provides pre-trained pipelines for common NLP tasks like text generation, summarization, and translation.\n",
        "* **logging:** Manages logging messages during training or inference.\n",
        "* **TextStreamer:** (Optional) Enables text streaming for large datasets, potentially improving memory efficiency during training.\n",
        "\n",
        "**From Peft:**\n",
        "\n",
        "* **LoraConfig:** Configuration for training with Low-Rank AdaGrad (LORA) for memory optimization.\n",
        "* **PeftModel:** Core class used to create and manage Peft models, enabling efficient fine-tuning.\n",
        "* **prepare_model_for_kbit_training:** Prepares the model for training with limited precision (e.g., 8-bit) using BitsAndBytes.\n",
        "* **get_peft_model:** Retrieves a Peft model for fine-tuning.\n",
        "\n",
        "**Standard Libraries:**\n",
        "\n",
        "* **os:** Provides operating system functionalities like path manipulation.\n",
        "* **torch:** The core deep learning library used for building and training models.\n",
        "* **platform:** Provides information about the system platform and environment.\n",
        "* **warnings:** Used to handle and manage warnings during code execution.\n",
        "\n",
        "**From Datasets:**\n",
        "\n",
        "* **load_dataset:** Loads datasets from the Hugging Face Hub or local files.\n",
        "* **Dataset, DatasetDict:** Classes for representing and managing datasets.\n",
        "\n",
        "**From TRL:**\n",
        "\n",
        "* **SFTTrainer:** A trainer class from the TRL library (potentially used for specific transfer learning approaches).\n",
        "\n",
        "**From Hugging Face Hub:**\n",
        "\n",
        "* **notebook_login:** Allows authentication with the Hugging Face Hub for potential model upload or download (optional).\n",
        "\n",
        "**Additional Libraries:**\n",
        "\n",
        "* **pandas (pd):** Used for data manipulation and analysis (potentially for data pre-processing or evaluation).\n",
        "* **sklearn.model_selection:** Provides functions for splitting data into training and validation sets.\n",
        "\n",
        "**Key Points:**\n",
        "\n",
        "* We leverage libraries from Hugging Face (Transformers and Datasets) for core NLP functionalities like model loading, tokenization, and dataset access.\n",
        "* Peft and TRL libraries offer additional functionalities related to efficient fine-tuning and transfer learning techniques.\n",
        "* Standard libraries like `os`, `torch`, and `platform` provide essential functionalities for system interaction and deep learning operations.\n",
        "* `pandas` and `sklearn` might be used for data manipulation and processing tasks."
      ],
      "metadata": {
        "id": "2zb_VxuxJHrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, HfArgumentParser, TrainingArguments, pipeline, logging, TextStreamer\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "import os,torch, platform, warnings\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from trl import SFTTrainer\n",
        "from huggingface_hub import notebook_login\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "MtrG1D2JYHYE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking Your System Environment\n",
        "\n",
        "Before diving into the tutorial, it's essential to check your system's specifications to ensure it can handle the computational demands of working with deep learning models. This code snippet helps you gather this information:\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import platform\n",
        "\n",
        "def print_system_specs():\n",
        "  \"\"\"\n",
        "  Prints information about your system's hardware and software environment.\n",
        "  \"\"\"\n",
        "  # Check if CUDA is available\n",
        "  is_cuda_available = torch.cuda.is_available()\n",
        "  print(\"CUDA Available:\", is_cuda_available)\n",
        "\n",
        "  # Get the number of available CUDA devices\n",
        "  num_cuda_devices = torch.cuda.device_count()\n",
        "  print(\"Number of CUDA devices:\", num_cuda_devices)\n",
        "\n",
        "  if is_cuda_available:\n",
        "    for i in range(num_cuda_devices):\n",
        "      # Get CUDA device properties\n",
        "      device = torch.device('cuda', i)\n",
        "      print(f\"--- CUDA Device {i} ---\")\n",
        "      print(\"Name:\", torch.cuda.get_device_name(i))\n",
        "      print(\"Compute Capability:\", torch.cuda.get_device_capability(i))\n",
        "      print(\"Total Memory:\", torch.cuda.get_device_properties(i).total_memory, \"bytes\")\n",
        "\n",
        "  # Get CPU information\n",
        "  print(\"--- CPU Information ---\")\n",
        "  print(\"Processor:\", platform.processor())\n",
        "  print(\"System:\", platform.system(), platform.release())\n",
        "  print(\"Python Version:\", platform.python_version())\n",
        "\n",
        "print_system_specs()\n",
        "```\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "1. **Importing Libraries:**\n",
        "    * `torch`: This is the primary deep learning library used in this tutorial.\n",
        "    * `platform`: This standard Python library provides information about the system's platform and environment.\n",
        "\n",
        "2. **`print_system_specs()` function:**\n",
        "    * This function gathers and prints system information.\n",
        "    * **CUDA Check:** It checks if CUDA, a parallel computing platform for GPUs, is available using `torch.cuda.is_available()`.\n",
        "    * **Number of CUDA devices:** It retrieves the number of available CUDA devices with `torch.cuda.device_count()`.\n",
        "    * **CUDA device details (if available):** It iterates through each CUDA device, getting its name, compute capability, and total memory using `torch.cuda` functions.\n",
        "    * **CPU information:** It prints information about the CPU processor, operating system, and Python version using `platform` module functions.\n",
        "\n",
        "3. **Calling the Function:**\n",
        "    * The last line (`print_system_specs()`) executes the function, printing the gathered information to the console.\n",
        "\n",
        "**Running the Code:**\n",
        "\n",
        "1. Copy and paste the code into your Python environment or notebook.\n",
        "2. Run the code. It will display details like:\n",
        "    * Whether CUDA is available.\n",
        "    * The number of available CUDA devices (if any).\n",
        "    * Details about each CUDA device (name, compute capability, memory).\n",
        "    * CPU information (processor, operating system, Python version).\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "* **CUDA Availability:** If working with GPUs is beneficial for your task, having CUDA available is crucial. This allows leveraging the parallel processing power of GPUs for faster training and inference.\n",
        "* **Number of CUDA Devices:** If you have multiple GPUs, you might be able to utilize them for distributed training, further accelerating the process.\n",
        "* **CUDA Device Details:** Knowing the compute capability and memory of your GPU(s) helps you understand their processing power and limitations.\n",
        "* **CPU Information:** While GPUs are often preferred for deep learning, understanding your CPU specifications is still valuable, as some operations might still rely on it.\n",
        "\n",
        "This information can help you assess the suitability of your system for running the code effectively and potentially guide any adjustments needed for optimal performance."
      ],
      "metadata": {
        "id": "n5yE-I6zH7Nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_system_specs():\n",
        "    # Check if CUDA is available\n",
        "    is_cuda_available = torch.cuda.is_available()\n",
        "    print(\"CUDA Available:\", is_cuda_available)\n",
        "# Get the number of available CUDA devices\n",
        "    num_cuda_devices = torch.cuda.device_count()\n",
        "    print(\"Number of CUDA devices:\", num_cuda_devices)\n",
        "    if is_cuda_available:\n",
        "        for i in range(num_cuda_devices):\n",
        "            # Get CUDA device properties\n",
        "            device = torch.device('cuda', i)\n",
        "            print(f\"--- CUDA Device {i} ---\")\n",
        "            print(\"Name:\", torch.cuda.get_device_name(i))\n",
        "            print(\"Compute Capability:\", torch.cuda.get_device_capability(i))\n",
        "            print(\"Total Memory:\", torch.cuda.get_device_properties(i).total_memory, \"bytes\")\n",
        "    # Get CPU information\n",
        "    print(\"--- CPU Information ---\")\n",
        "    print(\"Processor:\", platform.processor())\n",
        "    print(\"System:\", platform.system(), platform.release())\n",
        "    print(\"Python Version:\", platform.python_version())\n",
        "print_system_specs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWETUohcYFGK",
        "outputId": "3a6a055b-d838-4a49-fb45-7958548f3b2d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available: True\n",
            "Number of CUDA devices: 1\n",
            "--- CUDA Device 0 ---\n",
            "Name: Tesla T4\n",
            "Compute Capability: (7, 5)\n",
            "Total Memory: 15835660288 bytes\n",
            "--- CPU Information ---\n",
            "Processor: x86_64\n",
            "System: Linux 6.1.58+\n",
            "Python Version: 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Pretrained Tokenizer for Weight Transfer Transformer Tutorial\n",
        "\n",
        "This section focuses on loading a pre-trained tokenizer using the `AutoTokenizer` function from the `transformers` library. Here's a breakdown of the code:\n",
        "\n",
        "1. **`model_name`:** This variable stores the name of the pre-trained model you intend to use for weight transfer, but it's not directly used in this code snippet.\n",
        "2. **`tokenizer_name`:** This variable holds the name of the specific tokenizer that corresponds to the pre-trained model you're interested in.\n",
        "3. **`tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)`:** This line instantiates the `AutoTokenizer` class and loads the tokenizer identified by `tokenizer_name`. This tokenizer will be used to prepare your text data (e.g., tokenizing words and sentences) for compatibility with the pre-trained model you plan to utilize in the weight transfer process."
      ],
      "metadata": {
        "id": "V6IOU4G4bniS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilizing Mistral-7B-Instruct-v0.2 with SeaLLM-7B-v2's Tokenizer\n",
        "\n",
        "This section explores the chosen models for the transfer learning approach and the rationale behind using SeaLLM-7B-v2's tokenizer with Mistral-7B-Instruct-v0.2:\n",
        "\n",
        "**Chosen Models:**\n",
        "\n",
        "* **Source Model:**\n",
        "    * **Name:** Mistral-7B-Instruct-v0.2 ([https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2))\n",
        "    * **Type:** Encoder only model\n",
        "    * **Language:** English\n",
        "    * **Strengths:** Potential for generating different creative text formats, like poems, code, scripts, musical pieces, email, letters, etc.\n",
        "\n",
        "* **Destination Model:**\n",
        "    * **Name:** SeaLLM-7B-v2 ([https://huggingface.co/models?other=LLM](https://huggingface.co/SeaLLMs/SeaLLM-7B-v2))\n",
        "    * **Type:** Encoder only model\n",
        "    * **Languages:** Vietnamese, Indonesian, Thai, Malay, Khmer, Lao, Tagalog, Burmese\n",
        "    * **Strengths:** Powerful language understanding and generation capabilities, particularly for Southeast Asian languages.\n",
        "\n",
        "**Rationale for Tokenizer Replacement:**\n",
        "\n",
        "While both models are large language models (LLMs), they have key differences:\n",
        "\n",
        "* **Language Focus:** Mistral-7B-Instruct-v0.2 focuses on English, while SeaLLM-7B-v2 supports eight Southeast Asian languages.\n",
        "* **Task-Specific Fine-tuning:** Mistral-7B-Instruct-v0.2 is fine-tuned for instruction-based tasks, which might influence its vocabulary and tokenization scheme.\n",
        "\n",
        "**The key reason for using SeaLLM-7B-v2's tokenizer with Mistral-7B-Instruct-v0.2 is to handle potential vocabulary and tokenization misalignments.**\n",
        "\n",
        "* **Scenario:** If you plan to use Mistral-7B-Instruct-v0.2 for tasks requiring vocabulary specific to Southeast Asian languages, its original tokenizer might not be equipped for this new domain.\n",
        "* **Solution:** By using SeaLLM-7B-v2's tokenizer, you leverage its understanding of the relevant vocabulary and tokenization for these languages, potentially enhancing the performance of Mistral-7B-Instruct-v0.2 when applied to such tasks.\n",
        "\n",
        "**Code Snippet:**\n",
        "\n",
        "```python\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "tokenizer_name = \"SeaLLMs/SeaLLM-7B-v2\"\n",
        "\n",
        "```\n",
        "\n",
        "**Important Note:**\n",
        "\n",
        "While this approach can be beneficial in specific scenarios, it's crucial to carefully evaluate the potential benefits and drawbacks depending on your specific task and desired outcomes. Misalignment between the model's architecture and the borrowed tokenizer can lead to unintended consequences. It's recommended to experiment and compare the performance with and without this approach for your specific use case.\n",
        "\n",
        "**References:**\n",
        "\n",
        "* Mistral-7B-Instruct-v0.2 Model Card: [https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)\n",
        "* SeaLLM-7B-v2 Model Card: [https://huggingface.co/SeaLLMs/SeaLLM-7B-v2](https://huggingface.co/models?other=LLM)\n"
      ],
      "metadata": {
        "id": "sx_5cHjFMVvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Model and Tokenizer\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "tokenizer_name = \"SeaLLMs/SeaLLM-7B-v2\""
      ],
      "metadata": {
        "id": "kKrP-F0ntG4w"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using `huggingface-cli login` for Secure Access and Management\n",
        "\n",
        "While you won't need this command in the specific scenario of using SeaLLM-7B-v2, understanding `huggingface-cli login` is valuable for managing private models on the Hugging Face Hub. Here's an explanation:\n",
        "\n",
        "**What is `huggingface-cli login`?**\n",
        "\n",
        "The `huggingface-cli login` command is a tool provided by the Hugging Face Hub for securely logging in to your Hugging Face account from the command line. This login allows you to:\n",
        "\n",
        "* **Manage private models:** Access, upload, and manage private models stored on your Hugging Face Hub account. Public models don't require login for usage.\n",
        "* **Track and manage experiments:** Keep track of your experiments and associated versions uploaded to the Hub.\n",
        "* **Contribute to the Hub community:** Collaborate on projects, share models, and access models shared by other logged-in users.\n",
        "\n",
        "**When to use `huggingface-cli login`:**\n",
        "\n",
        "* When you want to upload your own trained models to the Hugging Face Hub for private storage or sharing with collaborators.\n",
        "* When you want to access and manage models uploaded by other users that have shared access privileges with you.\n",
        "\n",
        "**How to use `huggingface-cli login`:**\n",
        "\n",
        "1. **Install the `transformers` library:** If you haven't already, install the `transformers` library, which includes the `huggingface-cli` tool:\n",
        "\n",
        "```bash\n",
        "pip install transformers\n",
        "```\n",
        "\n",
        "2. **Run the command:**\n",
        "\n",
        "```bash\n",
        "huggingface-cli login\n",
        "```\n",
        "\n",
        "3. **Follow the instructions:** You'll be prompted to enter your Hugging Face Hub username and password.\n",
        "\n",
        "**Security:**\n",
        "\n",
        "* The `huggingface-cli login` command uses secure authentication methods to protect your credentials. It avoids storing your password directly on your machine.\n",
        "* It's crucial to keep your username and password confidential to maintain the security of your models and avoid unauthorized access.\n",
        "\n",
        "**Additional Notes:**\n",
        "\n",
        "* You can manage your login tokens and access settings directly from the Hugging Face Hub user interface ([https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)).\n",
        "* Refer to the official documentation for more details and advanced usage: [https://huggingface.co/docs/huggingface_hub/en/quick-start](https://huggingface.co/docs/huggingface_hub/en/quick-start)\n",
        "\n",
        "While you won't need this command for the specific models used in your tutorial, understanding its purpose and usage might be valuable for future projects involving private models or collaboration on the Hugging Face Hub."
      ],
      "metadata": {
        "id": "c4exaSkOOe05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "ufbRSBwJOcJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f0bccec-286c-4127-ff49-a78c5837abea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Efficiently Loading Tokenizers for NLP Tasks\n",
        "\n",
        "This section delves into the code snippet `tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)`, explaining its role and functionalities within your transfer learning tutorial:\n",
        "\n",
        "**Purpose:**\n",
        "\n",
        "This line of code is responsible for **loading the tokenizer associated with a specific pre-trained model** named by `tokenizer_name`.\n",
        "\n",
        "**Breakdown:**\n",
        "\n",
        "* **`AutoTokenizer`:** This class from the Transformers library automatically identifies and loads the appropriate tokenizer for the given model name. This eliminates the need for remembering or manually specifying the exact tokenizer class name, simplifying the process.\n",
        "* **`.from_pretrained(tokenizer_name)`:** This method calls the `from_pretrained` function of the `AutoTokenizer` class.\n",
        "    * **`tokenizer_name` (argument):** This argument specifies the name of the pre-trained model or tokenizer you want to load. In your case, it will be the name of the tokenizer you want to use (e.g., `\"SeaLLMs/SeaLLM-7B-v2\"`).\n",
        "\n",
        "**Functionalities:**\n",
        "\n",
        "The loaded tokenizer is responsible for:\n",
        "\n",
        "* **Preprocessing text data:** This involves tasks like splitting text into words or subwords (tokens), handling special characters, and potentially applying additional transformations specific to the model's requirements.\n",
        "* **Converting text to numerical representations:** The tokenizer converts the preprocessed tokens into numerical encodings that the model can understand and process during training and inference.\n",
        "* **Handling special tokens:** Tokenizers often define special tokens like padding tokens to ensure sequences have the same length and delimiters like start-of-sequence (SOS) and end-of-sequence (EOS) tokens for contextual understanding.\n",
        "\n",
        "**Benefits of `AutoTokenizer`:**\n",
        "\n",
        "* **Efficiency:** It simplifies the process by automatically fetching the correct tokenizer, saving you from manually searching for the corresponding class name.\n",
        "* **Flexibility:** It works with various pre-trained models from the Hugging Face Hub, making it adaptable to different scenarios within your transfer learning workflow.\n",
        "\n",
        "**Example Usage:**\n",
        "\n",
        "```python\n",
        "tokenizer_name = \"bert-base-uncased\"  # Example model name\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "\n",
        "# Example usage: Tokenize a sentence\n",
        "sentence = \"This is a sample sentence.\"\n",
        "encoded_text = tokenizer(sentence, return_tensors=\"pt\")  # Tokenize and convert to tensors\n",
        "```\n"
      ],
      "metadata": {
        "id": "oODwpHtqPX7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyzing Tokenizer Behavior\n",
        "This section delves into the analysis of the provided tokenizers, highlighting key observations and potential implications for your transfer learning task:\n",
        "\n",
        "**1. Code Breakdown:**\n",
        "\n",
        "- **`tokenizer_list`:** This list contains the names of the two tokenizers being compared: Mistral-7B-Instruct-v0.2 and SeaLLM-7B-v2.\n",
        "- **Processing Loop:**\n",
        "    - The code iterates through each tokenizer name.\n",
        "    - It loads the corresponding tokenizer using `AutoTokenizer.from_pretrained`.\n",
        "    - Sets the padding token and end-of-sentence token to be the same (`tokenizer.eos_token`) for consistency.\n",
        "    - Defines an example input text in Burmese (မျက်စိနာတာကို မကူးစက်အောင် ဘယ်လိုကာကွယ်ကြမလဲ!).\n",
        "    - Tokenizes the input text using `tokenizer.tokenize`.\n",
        "    - Prints the tokenized output and its length.\n",
        "    - Retrieves the tokenizer's vocabulary size using `tokenizer.vocab_size`.\n",
        "    - Appends the token count and vocabulary size to respective lists for comparison.\n",
        "\n",
        "**2. Observations:**\n",
        "\n",
        "- **Number of Tokens:**\n",
        "    - **Mistral-7B-Instruct-v0.2:** Tokenizes the input text into 64 tokens.\n",
        "    - **SeaLLM-7B-v2:** Tokenizes the same text into only 14 tokens.\n",
        "- **Vocabulary Size:**\n",
        "    - **Mistral-7B-Instruct-v0.2:** Has a vocabulary size of 32,000.\n",
        "    - **SeaLLM-7B-v2:** Has a vocabulary size of 48,384.\n",
        "\n",
        "**3. Implications for Transfer Learning:**\n",
        "\n",
        "- **Tokenization Discrepancy:** The significant difference in the number of tokens generated by each tokenizer.\n",
        "\n",
        "- **Vocabulary Size:** While the SeaLLM-7B-v2 has a larger vocabulary, it also generates fewer tokens. This suggests it might have a more efficient vocabulary representation for capturing information.\n",
        "\n",
        "**4. Recommendations:**\n",
        "\n",
        "- Carefully analyze the tokenization behavior of both models to understand potential challenges and explore mitigation strategies.\n",
        "- Consider techniques like subword segmentation or vocabulary alignment to bridge the gap between the tokenization styles of the source and destination models.\n",
        "- Experiment with different transfer learning approaches and evaluate the impact of tokenization differences on the final model performance.\n",
        "\n",
        "**Note:** This analysis provides a starting point for understanding the potential impact of tokenizer differences. Further investigation and experimentation are crucial to optimize your transfer learning process.\n"
      ],
      "metadata": {
        "id": "F8Kr2jkDRpux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_list = [\"mistralai/Mistral-7B-Instruct-v0.2\",\"SeaLLMs/SeaLLM-7B-v2\",]\n",
        "\n",
        "# Initialize lists to store token counts and vocabulary sizes\n",
        "token_counts = []\n",
        "vocab_sizes = []\n",
        "\n",
        "for tokenizer_name in tokenizer_list:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    input_text = \"မျက်စိနာတာကို မကူးစက်အောင် ဘယ်လိုကာကွယ်ကြမလဲ!\"\n",
        "    output = tokenizer.tokenize(input_text)\n",
        "    print(\"------\",tokenizer_name,\"------\")\n",
        "    print(output)\n",
        "    print('Number of tokens (Input Text)',len(output))\n",
        "\n",
        "    # Get the length of the tokenizer's vocabulary\n",
        "    vocab_size = tokenizer.vocab_size\n",
        "    print(\"Vocabulary size of tokenizer:\", vocab_size)\n",
        "\n",
        "    # Append token count and vocabulary size to the lists\n",
        "    token_counts.append(len(output))\n",
        "    vocab_sizes.append(vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JcEhBe4K5k7",
        "outputId": "b1c24a54-ce49-4967-8439-7887368d72ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------ mistralai/Mistral-7B-Instruct-v0.2 ------\n",
            "['▁', 'မ', '<0xE1>', '<0x80>', '<0xBB>', 'က', '်', 'စ', 'ိ', 'န', 'ာ', 'တ', 'ာ', 'က', 'ိ', 'ု', '▁', 'မ', 'က', '<0xE1>', '<0x80>', '<0xB0>', 'း', 'စ', 'က', '်', 'အ', 'ေ', 'ာ', 'င', '်', '▁', '<0xE1>', '<0x80>', '<0x98>', '<0xE1>', '<0x80>', '<0x9A>', '်', '<0xE1>', '<0x80>', '<0x9C>', 'ိ', 'ု', 'က', 'ာ', 'က', '<0xE1>', '<0x80>', '<0xBD>', '<0xE1>', '<0x80>', '<0x9A>', '်', 'က', 'ြ', 'မ', '<0xE1>', '<0x80>', '<0x9C>', '<0xE1>', '<0x80>', '<0xB2>', '!']\n",
            "Number of tokens (Input Text) 64\n",
            "Vocabulary size of tokenizer: 32000\n",
            "------ SeaLLMs/SeaLLM-7B-v2 ------\n",
            "['▁မျက်', 'စိ', 'နာ', 'တာကို', '▁မ', 'ကူး', 'စက်', 'အောင်', '▁ဘယ်လို', 'ကာ', 'ကွယ်', 'ကြ', 'မလဲ', '!']\n",
            "Number of tokens (Input Text) 14\n",
            "Vocabulary size of tokenizer: 48384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define colors for each bar\n",
        "colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
        "\n",
        "# Plotting token counts\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.barh(tokenizer_list, token_counts, color=colors)\n",
        "plt.xlabel(\"Token Count\")\n",
        "plt.ylabel(\"Tokenizer\")\n",
        "plt.title(\"Tokenization Analysis - Token Counts\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plotting vocabulary sizes\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.barh(tokenizer_list, vocab_sizes, color=colors)\n",
        "plt.xlabel(\"Vocabulary Size\")\n",
        "plt.ylabel(\"Tokenizer\")\n",
        "plt.title(\"Tokenization Analysis - Vocabulary Sizes\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "id": "NzzOaawPQLzC",
        "outputId": "0ae3291c-0ac0-460a-b462-8a64d99c74e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Source and Destination Models: Preparation for Knowledge Transfer"
      ],
      "metadata": {
        "id": "uuUqc9rUSrlz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this tutorial, the following code snippet ensures you have the necessary tokenizer loaded to effectively handle text data and interact with the chosen model (Mistral-7B-Instruct-v0.2) while using the vocabulary and tokenization scheme specific to the SeaLLM-7B-v2 tokenizer.**"
      ],
      "metadata": {
        "id": "CFclmpVVQgku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)"
      ],
      "metadata": {
        "id": "J2_ovJlRNhAn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Here's a breakdown of the code snippets for loading the source and destination models, highlighting their roles and the applied quantization techniques for efficiency:\n",
        "\n",
        "**1. Configuring Quantization:**\n",
        "\n",
        "```python\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=False,\n",
        ")\n",
        "```\n",
        "\n",
        "- **Purpose:** Sets up quantization configuration for loading models with reduced precision for potential performance and memory benefits.\n",
        "- **BitsAndBytesConfig:** Utilizes the BitsAndBytes library for quantization techniques.\n",
        "- **Key Settings:**\n",
        "    - `load_in_4bit=True`: Loads model weights in 4-bit format for memory optimization.\n",
        "    - `bnb_4bit_quant_type=\"nf4\"`: Specifies the type of 4-bit quantization (likely \"near-float4\").\n",
        "    - `bnb_4bit_compute_dtype=torch.float16`: Uses 16-bit floating-point precision for computations, striking a balance between accuracy and efficiency.\n",
        "    - `bnb_4bit_use_double_quant=False`: Disables double quantization, likely for simplicity and compatibility.\n",
        "\n",
        "**2. Loading Model:**\n",
        "\n",
        "```python\n",
        "src_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map={\"\": 0}\n",
        ")\n",
        "```\n",
        "\n",
        "- **Key Arguments:**\n",
        "    - `model_name`: Name of the source model to load.\n",
        "    - `quantization_config=bnb_config`: Applies the defined quantization configuration.\n",
        "    - `device_map={\"\": 0}`: Specifies to load the model onto GPU device 0 for accelerated processing.\n",
        "\n",
        "\n",
        "**Key Points:**\n",
        "\n",
        "- Quantization can reduce model size and improve memory efficiency, potentially impacting speed.\n",
        "- The models are loaded onto a GPU for faster processing.\n",
        "- This setup prepares for transferring knowledge from the pre-trained source model to the destination model, aiming to enhance the capabilities of the destination model.\n",
        "\n",
        "**Remember:** Consider potential model compatibility and performance implications when adjusting quantization settings. Experimentation and careful evaluation are crucial for optimal results.\n"
      ],
      "metadata": {
        "id": "6ChD37XMcqLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load base model to transfer weight\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit= True,\n",
        "    bnb_4bit_quant_type= \"nf4\",\n",
        "    bnb_4bit_compute_dtype= torch.float16,\n",
        "    bnb_4bit_use_double_quant= False,\n",
        ")\n",
        "# Load base model source\n",
        "src_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map={\"\": 0}\n",
        ")\n",
        "# Load base model destination\n",
        "des_model = AutoModelForCausalLM.from_pretrained(\n",
        "    tokenizer_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map={\"\": 0}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "52922bddfc5d4844aec6a29da290532f",
            "35428debe85a4494a742970eb9dea703",
            "6ffff0ee51a349aa8adb39a231472317",
            "636125f5e63541ff861360a1ba5d1611",
            "dd8061524f544f0daee5b94ce251ed98",
            "5ffe847ecb3a422fac408544069d1b2f",
            "2e3c115bc75b4766a44b8ef61d8fead1",
            "93eb987f7e914d0dab6bfcb6b2513ce6",
            "86185c3635424ba8bf157d98addd3854",
            "68e6efb01fbd426a9c16316c5993aae1",
            "285978cbcbaa4a82b1b4b7724601c802"
          ]
        },
        "id": "e5LjskpdvJo6",
        "outputId": "150e7f12-6b74-465f-e941-6fc67f6114dc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52922bddfc5d4844aec6a29da290532f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding Input and Output Embeddings\n",
        "\n",
        "These lines of code are used to **explore the input and output embedding layers** of the source (Mistral-7B-Instruct-v0.2) and destination (SeaLLM-7B-v2) models.\n",
        "\n",
        "* **`get_input_embeddings()`**: This function retrieves the model's **input embedding layer**, responsible for transforming input tokens (words or subwords) into numerical representations suitable for processing by the model's internal layers.\n",
        "* **`get_output_embeddings()`**: This function retrieves the model's **output embedding layer**, responsible for transforming the final hidden state of the model back into the vocabulary space. This allows the model to generate text sequences by predicting the next token based on the encoded representation."
      ],
      "metadata": {
        "id": "ZOat0Z8dXJuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Source input\",src_model.get_input_embeddings())\n",
        "print(\"Destination input\",des_model.get_input_embeddings())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZm47NA9XJx5",
        "outputId": "8fc988ac-a410-480f-b6a3-fab8f152636c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source input Embedding(32000, 4096)\n",
            "Destination input Embedding(48384, 4096)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Source output\",src_model.get_output_embeddings())\n",
        "print(\"Destination output\",des_model.get_output_embeddings())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPixs2DKXKiP",
        "outputId": "70383a80-f87d-4345-b69d-1acb0774d81c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source output Linear(in_features=4096, out_features=32000, bias=False)\n",
            "Destination output Linear(in_features=4096, out_features=48384, bias=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_model.get_input_embeddings().state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A81kjdUuXiUM",
        "outputId": "57ac96ea-25f9-46b4-9910-0fdb94e5136a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
              "                       -0.0000e+00, -0.0000e+00],\n",
              "                      [-4.3640e-03, -1.0633e-04, -5.6152e-03,  ..., -5.0545e-05,\n",
              "                       -1.1520e-03,  1.5926e-04],\n",
              "                      [-1.7471e-03,  1.0300e-03,  3.7432e-05,  ...,  1.1826e-03,\n",
              "                        3.7003e-04,  3.2425e-04],\n",
              "                      ...,\n",
              "                      [ 4.4556e-03, -1.3199e-03,  4.1008e-04,  ..., -4.4823e-05,\n",
              "                        5.4321e-03,  1.3351e-03],\n",
              "                      [-5.5313e-04,  3.3569e-03,  3.2654e-03,  ...,  1.0834e-03,\n",
              "                        1.4648e-03,  9.1171e-04],\n",
              "                      [-3.7842e-03, -4.8637e-04, -5.7068e-03,  ...,  4.2114e-03,\n",
              "                       -4.1580e-04, -2.5330e-03]], device='cuda:0', dtype=torch.float16))])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "des_model.get_input_embeddings().state_dict()"
      ],
      "metadata": {
        "id": "r1yyzrsnXpyk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4c1bb8-f286-4f00-cf40-d7f54d4b6335"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[-3.5286e-04,  3.5667e-04, -8.6212e-04,  ...,  6.7711e-05,\n",
              "                       -2.7466e-04, -5.1880e-04],\n",
              "                      [-4.0588e-03,  1.0300e-03, -4.6997e-03,  ..., -1.1673e-03,\n",
              "                       -9.0027e-04, -8.8501e-04],\n",
              "                      [-1.8311e-03,  2.3556e-04, -9.9945e-04,  ...,  7.2479e-04,\n",
              "                       -8.5831e-04, -5.9128e-04],\n",
              "                      ...,\n",
              "                      [ 5.5847e-03, -1.0669e-05,  9.0790e-04,  ..., -1.4648e-03,\n",
              "                       -8.7738e-04, -2.7771e-03],\n",
              "                      [ 9.6893e-04,  1.8539e-03, -1.9989e-03,  ..., -4.9210e-04,\n",
              "                        1.0910e-03, -8.6975e-04],\n",
              "                      [ 2.6245e-03,  1.4572e-03,  7.8964e-04,  ..., -2.7008e-03,\n",
              "                       -9.0790e-04,  2.7313e-03]], device='cuda:0', dtype=torch.float16))])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "By printing the information from these functions, you can potentially:\n",
        "\n",
        "* **Compare the dimensions:** See if the input and output embedding dimensions are compatible between the two models. Significant differences might require adjustments during transfer learning.\n",
        "* **Gain insights into vocabulary size:** The size of the output embedding layer might indicate the model's vocabulary size, which could be relevant for understanding the models' capabilities.\n",
        "\n",
        "However, it's important to remember that simply observing the embedding layers might not provide extensive information about the models' inner workings or their transferability. It's crucial to analyze the overall architectures and consider other factors like the custom components and quantization used in the models."
      ],
      "metadata": {
        "id": "3eh1iowzWGEM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyzing Decoder Architectures: Key Components and Considerations"
      ],
      "metadata": {
        "id": "6pWK1a6AUUVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_model.get_decoder()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDAwbrXqXGCf",
        "outputId": "51e7521e-f461-43bb-a22c-e0a25dbac713"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MistralModel(\n",
              "  (embed_tokens): Embedding(32000, 4096)\n",
              "  (layers): ModuleList(\n",
              "    (0-31): 32 x MistralDecoderLayer(\n",
              "      (self_attn): MistralAttention(\n",
              "        (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "        (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "        (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "        (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "        (rotary_emb): MistralRotaryEmbedding()\n",
              "      )\n",
              "      (mlp): MistralMLP(\n",
              "        (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "        (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "        (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "        (act_fn): SiLU()\n",
              "      )\n",
              "      (input_layernorm): MistralRMSNorm()\n",
              "      (post_attention_layernorm): MistralRMSNorm()\n",
              "    )\n",
              "  )\n",
              "  (norm): MistralRMSNorm()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "des_model.get_decoder()"
      ],
      "metadata": {
        "id": "GYU8iWtLUOLj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62f424f2-8340-421b-c059-baeaa9688e93"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MistralModel(\n",
              "  (embed_tokens): Embedding(48384, 4096)\n",
              "  (layers): ModuleList(\n",
              "    (0-31): 32 x MistralDecoderLayer(\n",
              "      (self_attn): MistralAttention(\n",
              "        (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "        (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "        (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "        (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "        (rotary_emb): MistralRotaryEmbedding()\n",
              "      )\n",
              "      (mlp): MistralMLP(\n",
              "        (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "        (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "        (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "        (act_fn): SiLU()\n",
              "      )\n",
              "      (input_layernorm): MistralRMSNorm()\n",
              "      (post_attention_layernorm): MistralRMSNorm()\n",
              "    )\n",
              "  )\n",
              "  (norm): MistralRMSNorm()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Here's a breakdown of the decoder architectures for both models, highlighting crucial components and considerations for transfer learning:\n",
        "\n",
        "**Shared Characteristics:**\n",
        "\n",
        "- **Embedding Layer:** Both models start with an embedding layer that maps input tokens to dense vector representations.\n",
        "- **LayerStack:** They both utilize a `ModuleList` structure containing multiple decoder layers for sequential processing.\n",
        "- **Layer Normalization:** Each decoder layer employs normalization techniques to stabilize training and improve convergence.\n",
        "\n",
        "**Architecture-Specific Elements:**\n",
        "\n",
        "**Mistral Model:**\n",
        "\n",
        "- **MistralDecoderLayer:**\n",
        "    - **MistralAttention:** Custom attention mechanism with quantized linear transformations and a rotary embedding for potential efficiency and modeling capabilities.\n",
        "    - **MistralMLP:** Custom MLP with quantized layers and SiLU activation for non-linearity.\n",
        "    - **MistralRMSNorm:** Custom RMS normalization layer.\n",
        "\n",
        "**SeaLLM Model:**\n",
        "- **MistralDecoderLayer:**\n",
        "    - **MistralAttention:** Custom attention mechanism with quantized linear transformations and a rotary embedding for potential efficiency and modeling capabilities.\n",
        "    - **MistralMLP:** Custom MLP with quantized layers and SiLU activation for non-linearity.\n",
        "    - **MistralRMSNorm:** Custom RMS normalization layer.\n",
        "\n",
        "**Key Considerations for Transfer Learning:**\n",
        "\n",
        "- **Compatibility:** Examine the compatibility of layer types and dimensions to ensure smooth transfer of weights.\n",
        "- **Custom Components:** Understand the effects of custom components like `MistralAttention` and `MistralMLP` on compatibility and potential knowledge transfer.\n",
        "- **Quantization:** Be mindful of quantization differences and potential compatibility issues when transferring weights between quantized and non-quantized models.\n",
        "- **Experimentation:** Explore different transfer strategies, such as transferring all layers or selective layers, based on architecture similarities and knowledge transfer goals.\n",
        "\n",
        "**By carefully analyzing these decoder architectures and considering their implications, you can make informed choices about suitable transfer learning approaches and potentially achieve effective knowledge transfer between the models.**\n"
      ],
      "metadata": {
        "id": "6ju0w_1sTn4B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. `embed_tokens` (Embedding layer):**\n",
        "\n",
        "- This layer maps each input token (word) in a sequence to a dense embedding vector of size 4096. This embedding process captures semantic relationships between words.\n",
        "- The parameter `48384` indicates the vocabulary size (the number of unique words the model can handle).\n",
        "\n",
        "**2. `layers` (ModuleList):**\n",
        "\n",
        "- This module list holds 32 instances of `MistralDecoderLayer`, forming the core network of the model.\n",
        "- Each `MistralDecoderLayer` applies two main sub-layers: self-attention and a feed-forward network (MLP).\n",
        "\n",
        "**3. `MistralDecoderLayer`:**\n",
        "\n",
        "- This class represents a single processing step within the network.\n",
        "- **`self_attn` (MistralAttention):**\n",
        "    - This sub-layer performs **self-attention**, analyzing the relationships between words within the same input sequence.\n",
        "    - It uses multiple linear projections (`Linear4bit`) to generate query (`q_proj`), key (`k_proj`), and value (`v_proj`) vectors for each token.\n",
        "    - Additionally, it employs a `MistralRotaryEmbedding` layer, which is a specific type of positional encoding mechanism not commonly found in standard transformer implementations.\n",
        "- **`mlp` (MistralMLP):**\n",
        "    - This sub-layer acts as a feed-forward network, transforming the output of the self-attention layer.\n",
        "    - It uses linear projections (`Linear4bit`) for the gate projection (`gate_proj`), the upward projection (`up_proj`), and the downward projection (`down_proj`).\n",
        "    - The activation function (`act_fn`) is a specific type called \"SiLU\" (Sigmoid Linear Unit).\n",
        "- **`input_layernorm` and `post_attention_layernorm` (MistralRMSNorm):**\n",
        "    - These layers use a specific form of layer normalization (`MistralRMSNorm`) to stabilize the training process.\n",
        "\n",
        "**4. `norm` (MistralRMSNorm):**\n",
        "\n",
        "- This final layer applies another normalization step to the output of the entire network."
      ],
      "metadata": {
        "id": "1aJT6wQ-dPbe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding size of mistralai/Mistral-7B-Instruct-v0.2 is 32000.\n",
        "\n",
        "Embedding size of SeaLLMs/SeaLLM-7B-v2 is 48384."
      ],
      "metadata": {
        "id": "y54RhxV2Xw7O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing Knowledge Transfer with Configuration Options\n",
        "\n",
        "This section outlines the code for implementing knowledge transfer based on your choices:\n",
        "\n",
        "```python\n",
        "# Configuration options (replace with your actual choices)\n",
        "transfer_input_embeddings = True\n",
        "transfer_output_embeddings = False\n",
        "transfer_decoder = True\n",
        "\n",
        "# Get vocabulary size of both models\n",
        "model_vocab_size = src_model.get_input_embeddings().num_embeddings\n",
        "tokenizer_vocab_size = len(tokenizer.vocab)\n",
        "\n",
        "# Check if tokenizer has a larger vocabulary\n",
        "if tokenizer_vocab_size > model_vocab_size:\n",
        "  print(\"Tokenizer vocabulary is larger than model's vocabulary. Adaptation is needed.\")\n",
        "  src_model.resize_token_embeddings(len(tokenizer))  # Adjust size if necessary\n",
        "\n",
        "# Perform knowledge transfer based on configuration\n",
        "if transfer_input_embeddings:\n",
        "  # Transfer input embeddings\n",
        "  src_model.get_input_embeddings().load_state_dict(des_model.get_input_embeddings().state_dict())\n",
        "\n",
        "if transfer_output_embeddings:\n",
        "  # Transfer output embeddings\n",
        "  src_model.get_output_embeddings().load_state_dict(des_model.get_output_embeddings().state_dict())\n",
        "\n",
        "if transfer_decoder:\n",
        "  # Transfer decoder weights\n",
        "  src_model.get_decoder().load_state_dict(des_model.get_decoder().state_dict())\n",
        "else:\n",
        "  print(\"Skipping decoder transfer based on your configuration.\")\n",
        "\n",
        "# Note: The code snippet does not handle the case where the tokenizer vocabulary is smaller than the model's, as it's generally not recommended.\n",
        "\n",
        "# Proceed with further training or fine-tuning the source model with transferred knowledge\n",
        "```\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "1. **Configuration:** Define variables like `transfer_input_embeddings`, `transfer_output_embeddings`, and `transfer_decoder` to reflect your desired transfer settings (replace with `True` or `False` based on your actual choices).\n",
        "2. **Vocabulary Check:** Check if the tokenizer's vocabulary size (`tokenizer_vocab_size`) is larger than the model's vocabulary size (`model_vocab_size`).\n",
        "    - If larger, a message is printed indicating adaptation might be needed.\n",
        "    - The code also includes the line `src_model.resize_token_embeddings(len(tokenizer))`, which is commented out by default. This line would adjust the source model's embedding layer size to match the tokenizer's vocabulary if needed. **Use this line with caution and carefully consider potential consequences before uncommenting.**\n",
        "3. **Knowledge Transfer:** Based on your configuration choices:\n",
        "    - If `transfer_input_embeddings` is `True`, the weights of the input embedding layer are copied from the destination model to the source model.\n",
        "    - If `transfer_output_embeddings` is `True`, the weights of the output embedding layer are copied from the destination model to the source model.\n",
        "    - If `transfer_decoder` is `True`, the weights of the decoder layer are copied from the destination model to the source model.\n",
        "    - If `transfer_decoder` is `False`, a message is printed stating the decoder transfer is skipped.\n",
        "\n",
        "**Remember:**\n",
        "\n",
        "- Experiment with different configuration options to explore the impact of knowledge transfer on the resulting model's performance.\n",
        "- Carefully consider potential compatibility issues and the implications of vocabulary size differences before adapting the model's embedding layer size."
      ],
      "metadata": {
        "id": "IQz5wGDoduQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Knowledge Transfer Configurations\n",
        "\n",
        "Here's a breakdown of the model's behavior for the three configurations you provided:\n",
        "\n",
        "**Configuration 1**\n",
        "\n",
        "* **Transfer Input Embeddings:** **Enabled**\n",
        "* **Transfer Output Embeddings:** **Disabled**\n",
        "* **Transfer Decoder:** **Disabled**\n",
        "\n",
        "In this scenario:\n",
        "\n",
        "- The source model's input embedding layer will be updated with weights from the destination model. This might help the source model understand the vocabulary and token representations used by the destination model, potentially improving its performance on tasks that align with the destination model's strengths.\n",
        "- The source model's output embedding layer and decoder layers will **not** be modified. This means the model's output vocabulary and decoding process will remain unchanged.\n",
        "\n"
      ],
      "metadata": {
        "id": "iYob2sw8a5N4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_input_embeddings = True\n",
        "transfer_output_embeddings = False\n",
        "transfer_decoder = False\n",
        "\n",
        "# Get vocabulary size of both models\n",
        "model_vocab_size = src_model.get_input_embeddings().num_embeddings\n",
        "tokenizer_vocab_size = len(tokenizer.vocab)\n",
        "\n",
        "# Check if tokenizer has a larger vocabulary\n",
        "if tokenizer_vocab_size > model_vocab_size:\n",
        "  print(\"Tokenizer vocabulary is larger than model's vocabulary. Adaptation is needed.\")\n",
        "  src_model.resize_token_embeddings(len(tokenizer))  # Adjust size if necessary\n",
        "\n",
        "if transfer_input_embeddings == True:\n",
        "  # Copy weights of the embedding layer from destination model to source\n",
        "  src_model.get_input_embeddings().load_state_dict(des_model.get_input_embeddings().state_dict())\n",
        "\n",
        "if transfer_output_embeddings == True:\n",
        "  src_model.get_output_embeddings().load_state_dict(des_model.get_output_embeddings().state_dict())\n",
        "\n",
        "if transfer_decoder == True:\n",
        "  # Copy weights of the decoder layer from destination model to source\n",
        "  src_model.get_decoder().load_state_dict(des_model.get_decoder().state_dict())\n",
        "\n",
        "else:\n",
        "    # Handle the case where tokenizer has smaller vocabulary (not recommended)\n",
        "    print(\"Tokenizer vocabulary is smaller than model's vocabulary. Adaptation not needed.\")\n"
      ],
      "metadata": {
        "id": "f7Mne6-l-b3P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4006ea9-c06e-4661-9383-7e80af2a6fe5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer vocabulary is larger than model's vocabulary. Adaptation is needed.\n",
            "Tokenizer vocabulary is smaller than model's vocabulary. Adaptation not needed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stream(user_prompt):\n",
        "    runtimeFlag = {\"\": 0}\n",
        "    system_prompt = 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n'\n",
        "    B_INST, E_INST = \"### Instruction:\\n\", \"### Response:\\n\"\n",
        "\n",
        "    prompt = f\"{system_prompt}{B_INST}{user_prompt.strip()}\\n\\n{E_INST}\"\n",
        "\n",
        "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(runtimeFlag)\n",
        "\n",
        "    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "\n",
        "    # Despite returning the usual output, the streamer will also print the generated text to stdout.\n",
        "    _ = src_model.generate(**inputs, streamer=streamer, max_new_tokens=100)"
      ],
      "metadata": {
        "id": "0y7hdCHNTRkP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stream(\"what is paracetamol\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdmcUaARTXHM",
        "outputId": "95756711-26b9-4b59-e2a7-14136ec050f8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Attempting to cast a BatchEncoding to type {'': 0}. This is not supported.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1477: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "无法報導orongສໍາລັບ人類 Pusဘယ်လို最新ຍາbolautri kanila kêu辦法柔维持 kayo病人 đặtလွယ် ພິ Làm sabu製品โรงเรียน社区បន្ទូលခဲສໍາເລັດ病人 digunakan chó較ပတ်သက် Joko罰 ပထမဆုံးສໍາເລັດ罰病人 kayoបន្ទូល罰 bậc membaca 全 phóng勃 ပထမဆုံး phónguncurkan đặtព្រះអង្គ賞เกิดขึ้นກໍ体制体制体制ົ່າMga umumnya体制体制 kond体制uci phóng维持ສໍາເລັດကဲ体制体制体制体制 phóng维持维持维持恆 nútကဲ ပထမဆုံး umumnya体制体制体制 ပထမဆုံး umumnya phóng以来 umumnya体制体制 ပထမဆုံး ပထမဆုံး ပထမဆုံး ပထမဆုံး成功 phóng\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stream(\"အမေရိကန်နိုင်ငံ\")"
      ],
      "metadata": {
        "id": "ETOCd133UYt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stream(\"မျက်စိနာတာကို မကူးစက်အောင် ဘယ်လိုကာကွယ်ကြမလဲ!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43E3nMocVF3T",
        "outputId": "7c8cb2ce-7cda-4f79-dcf1-28d6a8d4da91"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Attempting to cast a BatchEncoding to type {'': 0}. This is not supported.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ခေါင်း全面尽管迅 umumnya尽管နီးดีទឹក ນາຍ成功尽管ที่ผมទឹក Siapa Mab umumnya Ibrahim olehukai umumnya Lionelສໍາລັບ柔尽管နီး gue kelu Buka လုပ်ကိုင်ဂါโรงเรียน社区 tuy umumnya Lionel xanh Lionelສໍາລັບ peringkatព្រះអង្គ umumnya不過恆 koleksi Joko ពីរ体制体制បន្ទូលháສໍາເລັດ Lionelháទទួលâu体制ធាន giá較 Ibrahim Lionel重要 Lionelhá社交ធាន đặtpta体制 Lionelร์ Lionel Lionelร์邁合作 រីឯbiz体制体制柔 က်uci phónguci phóng体制 Lionel体制体制体制体制体制体制ဂါ phónguciuci phóng\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configuration 2**\n",
        "\n",
        "* **Transfer Input Embeddings:** **Enabled**\n",
        "* **Transfer Output Embeddings:** **Disabled**\n",
        "* **Transfer Decoder:** **Enabled**\n",
        "\n",
        "This configuration is similar to the first one, with the addition of decoder layer transfer:\n",
        "\n",
        "- The source model's input embedding layer and decoder layers will be updated with weights from the destination model. This might benefit tasks that involve the specific decoding capabilities of the destination model.\n",
        "- The source model's output embedding layer will **not** be modified, preserving its original vocabulary."
      ],
      "metadata": {
        "id": "Md0heWHEbQSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_input_embeddings = True\n",
        "transfer_output_embeddings = False\n",
        "transfer_decoder = True\n",
        "\n",
        "# Get vocabulary size of both models\n",
        "model_vocab_size = src_model.get_input_embeddings().num_embeddings\n",
        "tokenizer_vocab_size = len(tokenizer.vocab)\n",
        "\n",
        "# Check if tokenizer has a larger vocabulary\n",
        "if tokenizer_vocab_size > model_vocab_size:\n",
        "  print(\"Tokenizer vocabulary is larger than model's vocabulary. Adaptation is needed.\")\n",
        "  src_model.resize_token_embeddings(len(tokenizer))  # Adjust size if necessary\n",
        "\n",
        "if transfer_input_embeddings == True:\n",
        "  # Copy weights of the embedding layer from destination model to source\n",
        "  src_model.get_input_embeddings().load_state_dict(des_model.get_input_embeddings().state_dict())\n",
        "\n",
        "if transfer_output_embeddings == True:\n",
        "  src_model.get_output_embeddings().load_state_dict(des_model.get_output_embeddings().state_dict())\n",
        "\n",
        "if transfer_decoder == True:\n",
        "  # Copy weights of the decoder layer from destination model to source\n",
        "  src_model.get_decoder().load_state_dict(des_model.get_decoder().state_dict())\n",
        "\n",
        "else:\n",
        "    # Handle the case where tokenizer has smaller vocabulary (not recommended)\n",
        "    print(\"Tokenizer vocabulary is smaller than model's vocabulary. Adaptation not needed.\")\n"
      ],
      "metadata": {
        "id": "Mn1KqvxrbnzF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stream(\"what is paracetamol\")"
      ],
      "metadata": {
        "id": "i0-6vdWDbpPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da866338-0fea-4a48-fb24-946584bfae29"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Attempting to cast a BatchEncoding to type {'': 0}. This is not supported.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ស្លាប់ລົດ sulit知道နီ紋เรียမဆိုနီ phương dikatakanနာမဆို phươngulang出席 phươngໍາနာບານမဆို phương lượt permukaanမဆို phươngาศမဆို phươngitasiិសុទ្ធမဆို phương ကိုယ့်เรียนulang cố cố khẩnื้อมันก็ phươngitasi展開 Sandiမဆိုวลitasiakuanမယ္မဆို phươngเปลี่ยนulangมันก็itasi展開 tersedia扮ภัยมันก็展開寵 Sandikonfမဆိုນີ phương cố cốvoiภัยพันธitasi menegaskanภัย phươngwakမဆို扮 bìမဆိုကြ၏။ကြ၏။voi烤ကြ၏။ วัน伺itasiမဆိုမဆိုမဆို寵မဆိုលុយကြ၏။ยอม Mabမဆို\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stream(\"အမေရိကန်နိုင်ငံ\")"
      ],
      "metadata": {
        "id": "U7O-nLYFbrY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1251aa6-8009-40fa-e366-dd89db9343ca"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Attempting to cast a BatchEncoding to type {'': 0}. This is not supported.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "循環မဆို寵 simula展開မဆိုារ្យနာ yên paanoမဆို寵 yênຈະ မြို့ຶກမဆို phương ipinနီး主流 phương khẩn mataยอม phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương yênເວລາທີ່ phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương yênស្ថិត Gratis桑မဆို phương phương yênuciချက်တွေvoi phương yênោរពitasi phương拉克 diren menegaskan扮 phươngແລ评论bedaမဆို phươngແລပွား Sandi Ingat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stream(\"မျက်စိနာတာကို မကူးစက်အောင် ဘယ်လိုကာကွယ်ကြမလဲ!\")"
      ],
      "metadata": {
        "id": "kPivBAqqbts5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ad29d47-3a17-4b0d-a522-39c07f8162fe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Attempting to cast a BatchEncoding to type {'': 0}. This is not supported.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phố diren出席ดย ngại主流မဆိုနာធីអោយ permukaanမဆိုမဆို ທິ နိုင်่วàm主流 phátမဆို寵 Sandivoiမဆို phươngအသက် phương主流arap主流 ລວມ只有akuan PublikCha cặpulang phươngมันก็ phươngเปลี่ยนulang yên phương diren Chính ລວມakuan pendដាក់မဆို phươngมันก็itasiချက်တွေ keju phương phương phươngมันก็ Sandiចង់只有မဆို phươngเปลี่ยนมันก็ diren múမဆို phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương phương yênuciulangချက်တွေ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configuration 3**\n",
        "\n",
        "* **Transfer Input Embeddings:** **Enabled**\n",
        "* **Transfer Output Embeddings:** **Enabled**\n",
        "* **Transfer Decoder:** **Enabled**\n",
        "\n",
        "This configuration involves transferring weights across all three components:\n",
        "\n",
        "- The source model's input and output embedding layers, as well as the decoder layers, will be updated with weights from the destination model. This represents the most extensive transfer of knowledge, potentially leading to significant changes in the source model's behavior. It's crucial to carefully consider compatibility between the models and the potential impact on the source model's original functionalities.\n",
        "\n"
      ],
      "metadata": {
        "id": "4q-4PE06bUtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_input_embeddings = True\n",
        "transfer_output_embeddings = True\n",
        "transfer_decoder = True\n",
        "\n",
        "# Get vocabulary size of both models\n",
        "model_vocab_size = src_model.get_input_embeddings().num_embeddings\n",
        "tokenizer_vocab_size = len(tokenizer.vocab)\n",
        "\n",
        "# Check if tokenizer has a larger vocabulary\n",
        "if tokenizer_vocab_size > model_vocab_size:\n",
        "  print(\"Tokenizer vocabulary is larger than model's vocabulary. Adaptation is needed.\")\n",
        "  src_model.resize_token_embeddings(len(tokenizer))  # Adjust size if necessary\n",
        "\n",
        "if transfer_input_embeddings == True:\n",
        "  # Copy weights of the embedding layer from destination model to source\n",
        "  src_model.get_input_embeddings().load_state_dict(des_model.get_input_embeddings().state_dict())\n",
        "\n",
        "if transfer_output_embeddings == True:\n",
        "  src_model.get_output_embeddings().load_state_dict(des_model.get_output_embeddings().state_dict())\n",
        "\n",
        "if transfer_decoder == True:\n",
        "  # Copy weights of the decoder layer from destination model to source\n",
        "  src_model.get_decoder().load_state_dict(des_model.get_decoder().state_dict())\n",
        "\n",
        "else:\n",
        "    # Handle the case where tokenizer has smaller vocabulary (not recommended)\n",
        "    print(\"Tokenizer vocabulary is smaller than model's vocabulary. Adaptation not needed.\")\n"
      ],
      "metadata": {
        "id": "-svEea1Aby58"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stream(\"what is paracetamol\")"
      ],
      "metadata": {
        "id": "WjUnd076bz--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1048bbf-2837-4cd7-e286-6ab946c75634"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Attempting to cast a BatchEncoding to type {'': 0}. This is not supported.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Paracetamol, also known as acetaminophen, is a widely used analgesic and antipyretic medication that is commonly used to relieve mild to moderate pain and reduce fever. It is a type of analgesic that is often used to treat pain, fever, and other symptoms associated with common illnesses such as headaches, toothaches, and osteoarthritis. It is available in various forms, including tablets, capsules\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stream(\"အမေရိကန်နိုင်ငံ\")"
      ],
      "metadata": {
        "id": "YHTKwjwob2ZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8269bc5a-445c-4577-e2aa-c4d0b11b213d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Attempting to cast a BatchEncoding to type {'': 0}. This is not supported.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "အမေရိကန်နိုင်ငံသည် အရှေ့ဘက်ခြမ်းတွင် တည်ရှိပြီး ၁၉ ရာစုနှောင်းပိုင်းမှစ၍ ၁ ရာစုနှောင်းပိုင်းအထိ တည်ထောင်ခဲ့ပြီး၊ အရှေ့ဘက်ခြမ်းတွင် တည်ထောင်ခဲ့ပြီး၊ အရှေ့ဘက်ခြမ်းတွင် တည်ထောင်ခဲ့ပြီး၊ အရှေ့ဘက်ခြမ်းတွင် တည်ထောင်ခဲ့ပြီး၊ အရှေ့ဘက်ခြမ်းတွင် တည်ထောင်ခဲ့ပြီး၊ အရှေ့ဘက်ခြမ်းတွင် တည်ထောင်ခဲ့ပြီး၊ အရှေ့ဘက်ခြမ်းတွင် တည်ထောင်ခဲ့ပြီး၊ အရှေ့ဘက်\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stream(\"မျက်စိနာတာကို မကူးစက်အောင် ဘယ်လိုကာကွယ်ကြမလဲ!\")"
      ],
      "metadata": {
        "id": "lulZo43Ob4c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f0ee2f-f4a3-4d13-9a8b-6cb62626fe1b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Attempting to cast a BatchEncoding to type {'': 0}. This is not supported.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saccharomyces cerevisiae (S. cerevisiae) သည် မိုးဗီယို့ဗီ (Monilinia fructicola) နှင့်အတူ မိုးဗီယို့ဗီ (Monilinia fuscata) တို့၏ မျိုးဆက်သစ်များနှင့် ပေါင်းစပ်သော ပိုးမွှားများနှင့် ပိုးမွှားများမှ ထွက်ရှိသည့် ပိုးမွှားများနှင့် ပိုးမွှားများမှ ထွက်ရှိသည့် ပ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key Points:**\n",
        "\n",
        "- Each configuration offers a different level of knowledge transfer with varying degrees of potential impact on the source model's behavior.\n",
        "- Experimenting with these configurations and evaluating the results on your specific task is essential to determine the most effective approach for your use case.\n",
        "- Be cautious when enabling full knowledge transfer as it might lead to unintended consequences if the models have significant architectural differences or incompatible functionalities."
      ],
      "metadata": {
        "id": "CbksAzSTUgSn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modle fine-tuning (Coming soon!)"
      ],
      "metadata": {
        "id": "rXy1TUM_TkZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model\n",
        "src_model.save_pretrained(\"my_fine-tuned_model\")\n",
        "\n",
        "# Save and load the tokenizer after saving the model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"my_fine-tuned_model\")"
      ],
      "metadata": {
        "id": "yc8iTEv1yfEO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}